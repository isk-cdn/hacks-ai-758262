{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844d7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import ruclip\n",
    "import faiss\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c67920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка таблицы с данными книг и приведение пропусков к единому виду\n",
    "\n",
    "items = pd.read_csv('ds/items.csv', sep=';', index_col='sys_numb')\n",
    "items.replace({'отсутствует': '', 'none': '', '[б. и.]': '', np.nan: ''}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2e56ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "354355it [00:12, 28158.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#Формирование словаря с данными книг для построения эмбеддингов\n",
    "\n",
    "items_data = {}\n",
    "for _, item in tqdm(items.iterrows()):\n",
    "    if item['title'] == '':\n",
    "        continue\n",
    "    item_data = ' '.join([\n",
    "        item['title'],\n",
    "        item['author'].replace(', ', ' '),\n",
    "        #item['izd'].replace('Изд-во ', 'издательство').replace('Кн. изд-во ', 'издательство').replace('изд-во', 'издательство'),\n",
    "        item['year_izd'],\n",
    "        ' '.join(item['bbk'].split('\\n'))        \n",
    "    ])\n",
    "    item_data = item_data.replace('  ', ' ').replace('..', '').strip()\n",
    "    items_data[item.name] = item_data\n",
    "    \n",
    "item_ids = list(items_data.keys())\n",
    "item_titles = list(items_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08525ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 80/80 [14:43<00:00, 11.05s/it]\n"
     ]
    }
   ],
   "source": [
    "#Вычисление эмбеддингов книг с помощью модели RuClip\n",
    "\n",
    "batch_size = 4096\n",
    "clip, processor = ruclip.load('ruclip-vit-base-patch32-224', device=\"cuda\")\n",
    "predictor = ruclip.Predictor(clip, processor, \"cuda\", bs=batch_size)\n",
    "\n",
    "def tokenize_titles_batch(titles_batch):\n",
    "    with torch.no_grad():\n",
    "        title_embeddings = predictor.get_text_latents(titles_batch)\n",
    "    return title_embeddings.cpu().numpy()\n",
    "\n",
    "item_embeddings = None\n",
    "for batch_number in tqdm(range(len(item_titles) // batch_size + 1)):\n",
    "    batch_embeddings = tokenize_titles_batch(item_titles[batch_number*batch_size:(batch_number + 1) * batch_size])\n",
    "    if item_embeddings is None:\n",
    "        item_embeddings = batch_embeddings\n",
    "    else:\n",
    "        item_embeddings = np.concatenate((item_embeddings, batch_embeddings) , axis=0)\n",
    "        \n",
    "embeddings_dict = {item_ids[i]:item_embeddings[i] for i in range(len(item_embeddings))}\n",
    "items_ids =  list(embeddings_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85515d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import pickle\n",
    "with open('item_embeddings_dump1p.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d7bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построение индекса эмбеддингов с помощью библиотеки FAISS\n",
    "items_embeddings = np.array(list(embeddings_dict.values())).astype(np.float32)\n",
    "faiss_index = faiss.index_factory(512, 'Flat', faiss.METRIC_INNER_PRODUCT)\n",
    "faiss_index.add(items_embeddings)\n",
    "faiss.write_index(faiss_index, 'data/items.index1p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd13790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 507/507 [02:40<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#Поиск ближайших 20 соседей для каждой книги\n",
    "transactions = pd.read_csv('ds/train_transactions_extended.csv', sep=';', index_col=None, usecols={'sys_numb'})\n",
    "transactions = transactions['sys_numb'].tolist()\n",
    "\n",
    "recomendations_by_title = {}\n",
    "batch_size = 512\n",
    "for batch_number in tqdm(range(len(transactions) // batch_size + 1)):\n",
    "  batch = transactions[batch_number*batch_size:(batch_number+1)*batch_size]\n",
    "  embeddings = []\n",
    "  item_ids = []\n",
    "  for transaction_item_id in batch:\n",
    "    if transaction_item_id in embeddings_dict:\n",
    "      embeddings.append(embeddings_dict[transaction_item_id])\n",
    "      item_ids.append(transaction_item_id)\n",
    "\n",
    "  embeddings = np.array(embeddings)\n",
    "  distances, indexes = faiss_index.search(embeddings, 21)\n",
    "  for i, item_id in enumerate(item_ids):\n",
    "    recomendations_by_title[item_id] = [{items_ids[indexes[i][j]]: distances[i][j]} for j in range(1, len(indexes[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87936de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 16753/16753 [00:25<00:00, 661.42it/s]\n"
     ]
    }
   ],
   "source": [
    "#Построение рекомендаций на основе top-20 ближайших соседей\n",
    "\n",
    "transactions = pd.read_csv(\n",
    "    'ds/train_transactions_extended.csv',\n",
    "    sep=';',\n",
    "    index_col=None,\n",
    "    usecols = ('chb', 'sys_numb', 'date_1')\n",
    ")\n",
    "\n",
    "recommendations = []\n",
    "max_recommendations = 20\n",
    "\n",
    "\n",
    "for user in tqdm(set(transactions['chb'].unique())):\n",
    "    user_recommendations = []\n",
    "    user_transactions =  transactions[transactions['chb'] == user].sort_values('date_1', ascending=False)\n",
    "    \n",
    "    #1й этап - по каждому пользователю осуществляется сбор рекомендаций по тем книгам, которые он заказывал ранее\n",
    "    for _, transaction in user_transactions.iterrows():\n",
    "        book = transaction['sys_numb']\n",
    "        nearest_books = recomendations_by_title.get(book, [])\n",
    "        for nearest_book in nearest_books:\n",
    "            item, distance = tuple(nearest_book.items())[0]\n",
    "            user_recommendations.append({\n",
    "                'item': item,\n",
    "                'similarity': 1.001 - distance # превращение дистанции в подобие\n",
    "            })  \n",
    "    \n",
    "    #2й этап - все собранные рекомендации ранжируются по степени близости и отбирается top-20\n",
    "    recommendations_processed = {}\n",
    "    max_distance = 0\n",
    "    worst_item = None\n",
    "    \n",
    "    for recommendation in user_recommendations:\n",
    "        _item, _dist = recommendation.values()\n",
    "        if _item in recommendations_processed:\n",
    "            if recommendations_processed[_item] > _dist:\n",
    "                recommendations_processed[_item] = _dist\n",
    "        else:\n",
    "            if _dist < max_distance:\n",
    "                recommendations_processed[_item] = _dist\n",
    "                if len(recommendations_processed) >= max_recommendations:\n",
    "                    if not worst_item:\n",
    "                        worst_item = list(recommendations_processed.keys())[0]\n",
    "                    del recommendations_processed[worst_item]\n",
    "                    max_distance = max(list(recommendations_processed.values()))\n",
    "                    worst_item = list(\n",
    "                        recommendations_processed.keys()\n",
    "                    )[list(recommendations_processed.values()).index(max_distance)]\n",
    "            else:\n",
    "                if len(recommendations_processed) < max_recommendations:\n",
    "                    recommendations_processed[_item] = _dist\n",
    "                    worst_item = _item\n",
    "                    max_distance = _dist\n",
    "                \n",
    "    recommendations += [(user, r_item) for r_item in recommendations_processed.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d91da7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запись решения в файл\n",
    "result = pd.DataFrame(recommendations)\n",
    "result.columns = ['chb', 'sys_numb']\n",
    "result.sort_values(by=['chb'], inplace=True)\n",
    "result.to_csv('solutions/solution1w.csv', index=False, sep=';', line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050dfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
